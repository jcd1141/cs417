{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 10: Searching Analysis\n",
        "\n",
        "Paste your completed search functions below, then work through the three experiments.\n",
        "\n",
        "For each experiment: **run the code**, then **answer the questions** in the markdown cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Paste your four search functions here:\n",
        "# - sequential_search\n",
        "# - binary_search\n",
        "# - sequential_search_counted\n",
        "# - binary_search_counted\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Imports for the experiments\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Experiment 1: The Comparison Race\n",
        "\n",
        "Run both counted searches on sorted lists of increasing size and plot the comparison counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sizes = [10, 50, 100, 500, 1000, 5000, 10000]\n",
        "seq_counts = []\n",
        "bin_counts = []\n",
        "\n",
        "for n in sizes:\n",
        "    # Generate a sorted list of n items\n",
        "    test_list = list(range(n))\n",
        "    # Pick a random target (might or might not be in the list)\n",
        "    target = random.randint(0, n)\n",
        "\n",
        "    _, s_count = sequential_search_counted(test_list, target)\n",
        "    _, b_count = binary_search_counted(test_list, target)\n",
        "\n",
        "    seq_counts.append(s_count)\n",
        "    bin_counts.append(b_count)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(sizes, seq_counts, 'o-', label='Sequential Search', color='red')\n",
        "plt.plot(sizes, bin_counts, 'o-', label='Binary Search', color='blue')\n",
        "plt.xlabel('List Size (n)')\n",
        "plt.ylabel('Number of Comparisons')\n",
        "plt.title('Sequential vs Binary Search: Comparisons by List Size')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 1 Questions\n",
        "\n",
        "**Q1:** Describe the shape of each curve. Why does one grow so much faster than the other?\n",
        "\n",
        "*Your answer:*\n",
        "\n",
        "\n",
        "**Q2:** At what list size does the difference start to feel significant?\n",
        "\n",
        "*Your answer:*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Experiment 2: Best Case, Worst Case\n",
        "\n",
        "How much does performance vary depending on *where* the target is (or if it's there at all)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n = 10000\n",
        "test_list = list(range(n))\n",
        "\n",
        "# Sequential search: best case vs worst case\n",
        "_, seq_best = sequential_search_counted(test_list, test_list[0])      # first element\n",
        "_, seq_worst = sequential_search_counted(test_list, n + 1)            # not in list\n",
        "\n",
        "print(\"=== Sequential Search (n = 10,000) ===\")\n",
        "print(f\"Best case  (first element):  {seq_best} comparisons\")\n",
        "print(f\"Worst case (not in list):    {seq_worst} comparisons\")\n",
        "print()\n",
        "\n",
        "# Binary search: does target position matter?\n",
        "_, bin_first = binary_search_counted(test_list, test_list[0])         # first element\n",
        "_, bin_last = binary_search_counted(test_list, test_list[-1])         # last element\n",
        "_, bin_mid = binary_search_counted(test_list, test_list[n // 2])      # middle element\n",
        "_, bin_miss = binary_search_counted(test_list, n + 1)                 # not in list\n",
        "\n",
        "print(\"=== Binary Search (n = 10,000) ===\")\n",
        "print(f\"First element:    {bin_first} comparisons\")\n",
        "print(f\"Last element:     {bin_last} comparisons\")\n",
        "print(f\"Middle element:   {bin_mid} comparisons\")\n",
        "print(f\"Not in list:      {bin_miss} comparisons\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 2 Questions\n",
        "\n",
        "**Q3:** Why does sequential search have such a huge gap between best and worst case?\n",
        "\n",
        "*Your answer:*\n",
        "\n",
        "\n",
        "**Q4:** Why is binary search so consistent regardless of where the target is? What about the algorithm causes this?\n",
        "\n",
        "*Your answer:*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Experiment 3: When Is Sorting Worth It?\n",
        "\n",
        "Binary search requires sorted data, and sorting costs O(n log n). If you have an unsorted list and need to search it *k* times, when does it pay to sort first?\n",
        "\n",
        "**The two options:**\n",
        "- **Option A:** Sequential search each time. Total cost: k × n\n",
        "- **Option B:** Sort first (n log n), then binary search each time. Total cost: n log n + k × log n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q5: Calculate the crossover\n",
        "\n",
        "For n = 10,000: set the two cost formulas equal and solve for *k*. Show your work.\n",
        "\n",
        "*Your answer:*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math\n",
        "\n",
        "n = 10000\n",
        "log_n = math.log2(n)  # approximately 13.3\n",
        "\n",
        "# Try different values of k and compare total costs\n",
        "print(f\"n = {n}, log2(n) ≈ {log_n:.1f}\")\n",
        "print(f\"{'k':>5}  {'Option A (k×n)':>15}  {'Option B (n·log n + k·log n)':>30}  {'Winner':>8}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for k in [1, 2, 5, 10, 13, 14, 15, 20, 50, 100]:\n",
        "    cost_a = k * n\n",
        "    cost_b = n * log_n + k * log_n\n",
        "    winner = \"A\" if cost_a < cost_b else \"B\" if cost_b < cost_a else \"Tie\"\n",
        "    print(f\"{k:>5}  {cost_a:>15,.0f}  {cost_b:>30,.0f}  {winner:>8}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 3 Questions\n",
        "\n",
        "**Q6:** Does the experimental crossover match your calculation? If not, why might they differ?\n",
        "\n",
        "*Your answer:*\n",
        "\n",
        "\n",
        "**Q7:** Give a real-world example where you'd choose Option A (just search without sorting) and one where you'd choose Option B (sort first, then search).\n",
        "\n",
        "*Your answer:*\n"
      ]
    }
  ]
}