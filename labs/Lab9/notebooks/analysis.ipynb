{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9: Open Addressing Analysis\n",
    "\n",
    "In this notebook you'll run experiments on your `HashTableOpen` class to see how linear probing behaves under different conditions.\n",
    "\n",
    "**Step 1:** Paste your completed `HashTableOpen` class (including the `_TOMBSTONE` sentinel) into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Paste your HashTableOpen class here ──────────────────────────\n",
    "# Copy everything from src/hash_table_open.py and paste it below.\n",
    "# Include the _TOMBSTONE = object() line at the top.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Counting Probes\n",
    "\n",
    "How many probes (slot checks) does it take to insert items as the table fills up?\n",
    "\n",
    "Run the cell below. It inserts random keys into a table of size 100 and tracks how many probes each `put` requires. The chart shows how probe count grows as load factor increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def count_probes_on_put(ht, key, value):\n",
    "    \"\"\"Insert a key and return how many slots were checked.\"\"\"\n",
    "    start = ht._hash(key)\n",
    "    probes = 0\n",
    "    for step in range(ht.size):\n",
    "        idx = (start + step) % ht.size\n",
    "        probes += 1\n",
    "        slot = ht.table[idx]\n",
    "        if slot is None or slot is ht.__class__.__module__ and False:\n",
    "            break\n",
    "        if isinstance(slot, tuple) and slot[0] == key:\n",
    "            break\n",
    "    ht.put(key, value)\n",
    "    return probes\n",
    "\n",
    "# Run experiment\n",
    "SIZE = 100\n",
    "ht = HashTableOpen(size=SIZE)\n",
    "load_factors = []\n",
    "probe_counts = []\n",
    "\n",
    "random.seed(42)\n",
    "for i in range(SIZE - 1):  # fill to 99% (can't fill 100%)\n",
    "    key = f\"key_{random.randint(0, 999999)}\"\n",
    "    probes = count_probes_on_put(ht, key, i)\n",
    "    load_factors.append(ht.load_factor())\n",
    "    probe_counts.append(probes)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(load_factors, probe_counts, s=10, alpha=0.6)\n",
    "plt.xlabel('Load Factor')\n",
    "plt.ylabel('Probes per Insert')\n",
    "plt.title('Linear Probing: Probes vs Load Factor')\n",
    "plt.axvline(x=0.75, color='red', linestyle='--', label='75% full')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average probes at <50% load: {sum(p for l,p in zip(load_factors, probe_counts) if l < 0.5) / max(1, sum(1 for l in load_factors if l < 0.5)):.1f}\")\n",
    "print(f\"Average probes at >75% load: {sum(p for l,p in zip(load_factors, probe_counts) if l > 0.75) / max(1, sum(1 for l in load_factors if l > 0.75)):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What happens to the number of probes once the table is more than 75% full? Why does this happen?\n",
    "\n",
    "*Your answer:*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Visualize the Table\n",
    "\n",
    "Let's see what the table actually looks like at different load factors. Green = occupied, red = tombstone, gray = empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def visualize_table(ht, title=\"\"):\n",
    "    \"\"\"Show the table as a color-coded bar.\"\"\"\n",
    "    colors = []\n",
    "    for slot in ht.table:\n",
    "        if slot is None:\n",
    "            colors.append('lightgray')\n",
    "        elif slot is _TOMBSTONE:\n",
    "            colors.append('red')\n",
    "        else:\n",
    "            colors.append('seagreen')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 1.5))\n",
    "    ax.bar(range(len(colors)), [1]*len(colors), color=colors, edgecolor='white', width=1.0)\n",
    "    ax.set_xlim(-0.5, len(colors)-0.5)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('Slot Index')\n",
    "    ax.set_title(f'{title}  (load factor: {ht.load_factor():.0%}, {ht.count} items)')\n",
    "\n",
    "    legend = [\n",
    "        mpatches.Patch(color='seagreen', label='Occupied'),\n",
    "        mpatches.Patch(color='red', label='Tombstone'),\n",
    "        mpatches.Patch(color='lightgray', label='Empty'),\n",
    "    ]\n",
    "    ax.legend(handles=legend, loc='upper right', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Build a table and visualize at different stages\n",
    "SIZE = 40\n",
    "ht = HashTableOpen(size=SIZE)\n",
    "\n",
    "# Insert 15 items\n",
    "random.seed(7)\n",
    "keys = [f\"item_{random.randint(0, 9999)}\" for _ in range(15)]\n",
    "for k in keys:\n",
    "    ht.put(k, True)\n",
    "visualize_table(ht, \"After inserting 15 items\")\n",
    "\n",
    "# Delete 5 items\n",
    "for k in keys[:5]:\n",
    "    ht.delete(k)\n",
    "visualize_table(ht, \"After deleting 5 items\")\n",
    "\n",
    "# Insert 10 more\n",
    "for i in range(10):\n",
    "    ht.put(f\"new_{i}\", True)\n",
    "visualize_table(ht, \"After inserting 10 more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Look at the \"After deleting 5 items\" visualization. Do you see any clusters (groups of green slots next to each other)? Why do clusters form with linear probing?\n",
    "\n",
    "*Your answer:*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Chaining vs Open Addressing\n",
    "\n",
    "How does lookup time compare between the two approaches? We'll measure the average number of comparisons for `get()` at different load factors.\n",
    "\n",
    "We provide a simple chaining implementation below to compare against your open addressing table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class ChainingHashTable:\n",
    "    \"\"\"Simple chaining hash table for comparison.\"\"\"\n",
    "    def __init__(self, size=100):\n",
    "        self.size = size\n",
    "        self.table = [[] for _ in range(size)]\n",
    "        self.count = 0\n",
    "\n",
    "    def _hash(self, key):\n",
    "        return hash(key) % self.size\n",
    "\n",
    "    def put(self, key, value):\n",
    "        bucket = self.table[self._hash(key)]\n",
    "        for pair in bucket:\n",
    "            if pair[0] == key:\n",
    "                pair[1] = value\n",
    "                return\n",
    "        bucket.append([key, value])\n",
    "        self.count += 1\n",
    "\n",
    "    def get(self, key):\n",
    "        for pair in self.table[self._hash(key)]:\n",
    "            if pair[0] == key:\n",
    "                return pair[1]\n",
    "        raise KeyError(key)\n",
    "\n",
    "# Compare lookup times at different load factors\n",
    "SIZE = 1000\n",
    "load_targets = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "chaining_times = []\n",
    "probing_times = []\n",
    "\n",
    "for target in load_targets:\n",
    "    n_items = int(SIZE * target)\n",
    "    keys = [f\"k{i}\" for i in range(n_items)]\n",
    "\n",
    "    # Build both tables\n",
    "    chain_ht = ChainingHashTable(size=SIZE)\n",
    "    open_ht = HashTableOpen(size=SIZE)\n",
    "    for k in keys:\n",
    "        chain_ht.put(k, True)\n",
    "        open_ht.put(k, True)\n",
    "\n",
    "    # Time lookups\n",
    "    start = time.perf_counter()\n",
    "    for k in keys:\n",
    "        chain_ht.get(k)\n",
    "    chaining_times.append((time.perf_counter() - start) / n_items * 1_000_000)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    for k in keys:\n",
    "        open_ht.get(k)\n",
    "    probing_times.append((time.perf_counter() - start) / n_items * 1_000_000)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "x = range(len(load_targets))\n",
    "plt.bar([i - 0.15 for i in x], chaining_times, width=0.3, label='Chaining', color='steelblue')\n",
    "plt.bar([i + 0.15 for i in x], probing_times, width=0.3, label='Open Addressing', color='coral')\n",
    "plt.xticks(x, [f\"{int(t*100)}%\" for t in load_targets])\n",
    "plt.xlabel('Load Factor')\n",
    "plt.ylabel('Avg Lookup Time (microseconds)')\n",
    "plt.title('Chaining vs Open Addressing: Lookup Performance')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Load Factor | Chaining (us) | Open Addr (us)\")\n",
    "print(\"-\" * 45)\n",
    "for t, c, o in zip(load_targets, chaining_times, probing_times):\n",
    "    print(f\"    {t:.0%}      |    {c:.2f}       |    {o:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** At which load factor does open addressing start to perform worse than chaining? Why does chaining handle high load factors more gracefully?\n",
    "\n",
    "*Your answer:*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
